from typing import Optional
from config import DEFAULT_SYSTEM_PROMPT, DEFAULT_STOP_STRINGS, SAMPLE_RATE
import io
import torch
import torchaudio
import os
from boson_multimodal.data_types import ChatMLSample, Message, AudioContent
from boson_multimodal.serve.serve_engine import HiggsAudioServeEngine
from loguru import logger
from utility import normalize_text, encode_audio_base64, save_temp_audio, cleanup_temp_file, set_random_seed
import traceback
from fastapi import HTTPException
import argparse
import asyncio
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

higgs_engine: Optional[HiggsAudioServeEngine] = None

def prepare_chatml_sample(
    text: str,
    reference_audio_path: Optional[str] = None,
    reference_text: Optional[str] = None,
    system_prompt: str = DEFAULT_SYSTEM_PROMPT
) -> ChatMLSample:
    messages = []
    try:
        if system_prompt:
            sys_message = Message(role="system", content=system_prompt)
            messages.append(sys_message)
        if reference_audio_path and os.path.exists(reference_audio_path):
            logger.info(f"Adding reference audio: {reference_audio_path}")
            if reference_text:
                ref_user_message = Message(role="user", content=reference_text)
                messages.append(ref_user_message)
            else:
                ref_user_message = Message(role="user", content="Please clone this voice.")
                messages.append(ref_user_message)
            audio_base64 = encode_audio_base64(reference_audio_path)
            audio_content = AudioContent(raw_audio=audio_base64, audio_url="")
            ref_assistant_message = Message(role="assistant", content=[audio_content])
            messages.append(ref_assistant_message)
        text = normalize_text(text)
        user_message = Message(role="user", content=text)
        messages.append(user_message)
        chatml_sample = ChatMLSample(messages=messages)
        logger.debug(f"Created ChatMLSample with {len(messages)} messages")
        return chatml_sample
    except Exception as e:
        logger.error(f"Error in prepare_chatml_sample: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        fallback_messages = [
            Message(role="user", content=normalize_text(text))
        ]
        return ChatMLSample(messages=fallback_messages)

async def synthesize_speech(
    text: str,
    reference_audio_data: Optional[bytes] = None,
    reference_text: Optional[str] = None,
    temperature: float = 0.7,
    top_p: float = 0.95,
    top_k: int = 50,
    seed: Optional[int] = None
) -> bytes:
    if higgs_engine is None:
        raise HTTPException(status_code=500, detail="TTS engine not initialized")
    temp_file = None
    try:
        set_random_seed(seed)
        if reference_audio_data:
            logger.info(f"Processing reference audio ({len(reference_audio_data)} bytes)")
            temp_file = save_temp_audio(reference_audio_data)
        chatml_sample = prepare_chatml_sample(
            text=text,
            reference_audio_path=temp_file,
            reference_text=reference_text
        )
        logger.info(f"Generating audio for text: '{text[:100]}...'")
        if temp_file:
            logger.info(f"Using voice cloning with reference audio: {temp_file}")
        try:
            response = higgs_engine.generate(
                chat_ml_sample=chatml_sample,
                max_new_tokens=1024,
                temperature=temperature,
                top_k=top_k if top_k > 0 else None,
                top_p=top_p,
                stop_strings=DEFAULT_STOP_STRINGS,
                ras_win_len=7,
                ras_win_max_num_repeat=2,
                force_audio_gen=True
            )
        except Exception as gen_error:
            logger.error(f"Generation error: {gen_error}")
            logger.error(f"Generation traceback: {traceback.format_exc()}")
            logger.info("Retrying with minimal parameters...")
            response = higgs_engine.generate(
                chat_ml_sample=chatml_sample,
                max_new_tokens=512,
                temperature=0.8,
                force_audio_gen=True
            )
        if response.audio is None:
            raise HTTPException(status_code=500, detail="No audio generated by model")
        audio_tensor = torch.from_numpy(response.audio).unsqueeze(0)
        if hasattr(response, 'sampling_rate'):
            sample_rate = response.sampling_rate
        else:
            sample_rate = SAMPLE_RATE
        buffer = io.BytesIO()
        torchaudio.save(buffer, audio_tensor, sample_rate, format="WAV")
        audio_bytes = buffer.getvalue()
        logger.info(f"Generated audio: {len(audio_bytes)} bytes at {sample_rate}Hz")
        return audio_bytes
    except Exception as e:
        logger.error(f"Synthesis error: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Synthesis failed: {str(e)}")
    finally:
        if temp_file:
            cleanup_temp_file(temp_file)


if __name__ == "__main__":

    parser_description = "Test TTS Service"
    parser = argparse.ArgumentParser(description=parser_description)

    text = "This is a wonderful day!"
    reference_audio = None,
    temperature = 0.7
    top_p = 0.95
    top_k = 50
    seed = 200
    output = "output.wav"

    
    args = parser.parse_args()

    higgs_engine = HiggsAudioServeEngine("bosonai/higgs-audio-v2-generation-3B-base", "bosonai/higgs-audio-v2-tokenizer")


    reference_audio_data = None
    if text:
        # with open(reference_audio, "rb") as f:
        #     reference_audio_data = f.read()

        audio_bytes = asyncio.run(
        synthesize_speech(
            text= text,
            temperature= temperature,
            top_p= top_p,
            top_k= top_k,
            seed= seed
        )
        )

        with open(output, "wb") as f:
            f.write(audio_bytes)
            print(f"Audio written to {output}")