{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Model checkpoint\nmodel_checkpoint = \"gokaygokay/Flux-Prompt-Enhance\"\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\n# Model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n\nenhancer = pipeline('text2text-generation',\n                    model=model,\n                    tokenizer=tokenizer,\n                    repetition_penalty= 1.2,\n                    device=device)\n\nmax_target_length = 256\nprefix = \"enhance prompt: \"\n\nshort_prompt = \"a beautiful mountain in the style of anime japaneese cartoon style\"\nanswer = enhancer(prefix + short_prompt, max_length=max_target_length)\nfinal_answer = answer[0]['generated_text']\nprint(final_answer)\n\n# code contributed by Ayushman","metadata":{"execution":{"iopub.status.busy":"2024-10-19T05:40:27.291982Z","iopub.execute_input":"2024-10-19T05:40:27.292462Z","iopub.status.idle":"2024-10-19T05:41:10.518138Z","shell.execute_reply.started":"2024-10-19T05:40:27.292409Z","shell.execute_reply":"2024-10-19T05:41:10.516933Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f7d3739a7b4e8da8efb507cb88ff93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29238ff61074f43bf08737fbfa155bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fa9b1d3e7d8409aa7e06ffb488de1a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f293c6a5f983491f83672d97421fda55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c354419b7c70415b9eb76db1a77f1c8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"301ad3c6752a47dea3a3cb00e0d1cd25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e849d1ec7f4126a3ccc8e292edcf98"}},"metadata":{}},{"name":"stdout","text":"a large mountain in the center, japanese anime style, dark green and brown mountains with patches of snow, blue sky with scattered clouds above, sunlight casting shadows on the mountain slopes, some trees visible at the base of the mountain, small buildings near the base of the mountain, clear day with bright natural light, no humans or animals present, detailed illustration with a realistic yet slightly stylized appearance\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text-to-Text Generation with Transformers\n\nThis Python code demonstrates how to use the Hugging Face `transformers` library to create a text-to-text generation pipeline, utilizing the model checkpoint `gokaygokay/Flux-Prompt-Enhance` to enhance a given text prompt.\n\n### Prerequisites\n- Install Hugging Face's `transformers` and `torch` libraries.\n\n```bash\npip install transformers torch\n```\n\n### Code Breakdown\n\n1. **Importing Required Modules**\n   * `pipeline`, `AutoTokenizer`, and `AutoModelForSeq2SeqLM` are imported from the `transformers` library to set up the text-to-text generation pipeline.\n\n2. **Device Setup**\n   * The code checks if a GPU is available using CUDA, otherwise it defaults to CPU:\n   ```python\n   device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n   ``` \n### Model Checkpoint\n\n*   The model checkpoint `\"gokaygokay/Flux-Prompt-Enhance\"` is specified for use:\n   ```python\n   model_checkpoint = \"gokaygokay/Flux-Prompt-Enhance\"\n```\n    ### Tokenizer and Model Initialization\n\n*   The tokenizer and model are loaded from the pre-trained model specified by the checkpoint:\n   ```python\n   tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n   model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n```\n### Pipeline Creation\n\n*   A `text2text-generation` pipeline is created using the specified model and tokenizer, with a repetition penalty of 1.2 to adjust the diversity of the generated text. The device (either `CPU` or `GPU`) is automatically selected based on availability:\n   ```python\n   enhancer = pipeline('text2text-generation', model=model, tokenizer=tokenizer, repetition_penalty=1.2, device=device)\n```\n    ### Prompt Enhancement\n\n* A prompt is enhanced by appending it to a predefined prefix `\"enhance prompt: \"` and passing it into the pipeline. The maximum target length for the output is set to 256 tokens:\n   ```python\n   max_target_length = 256\n   prefix = \"enhance prompt: \"\n   short_prompt = \"a beautiful mountain in the style of anime japaneese cartoon style\"\n   answer = enhancer(prefix + short_prompt, max_length=max_target_length)\n```\n### Final Output\n\n* The enhanced version of the prompt is extracted from the pipeline's output and printed:\n   ```python\n   final_answer = answer[0]['generated_text']\n   print(final_answer)\n","metadata":{}}]}